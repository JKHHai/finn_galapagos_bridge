# Overview
This repository contains the following files:
1. finn_galapagos.py: A python script that contains functions that will assist the user in creating a Galapagos Logical File for their FINN cores and get parameters for bridges.
2. finn_helper.py: A python script that contains functions that will make working in FINN's container easier. **This script must be copied into or run inside a FINN docker container**.

# finn_galapagos.py 
## finn_galapagos Requirements
- onnx
## finn_galapagos API
These are the most important/useful functions for users. Other functions are internal.
**get_parameters_for_bridges(streaming_fclayer_node):**
- Input: 
  - streaming_fclayer_node: An ONNX node object. Feed in the node object representing a StreamingFCLayer node. 
    - Despite all of FINN's transformations, the models generated by FINN are still in the ONNX format, and therefore can be read by ONNX.
- Function:
  - Determines the parameters needed to insert axi_stream_to_galapagos_bridges or galapagos_to_axi_stream_bridges before or after this StreamingFCLayer IP core. - Output:
  - Returns a dictionary containing "input_data_width" (in bits), "input_num_transfers", "output_data_width" (in bits), "output_num_transfers" parameters for the given streaming_fc_layer_node. 
  
**create_logical_file_for_finn_model(model):**
- Input:
  - model: An ONNX model. Feed in the parent model generated by FINN. 
  - IMPORTANT: The "ipgen_path" attribute of all accelerated nodes and StreamingDataFlowPartition "model" attribute must contain accurate filepaths, or this function will work incorrectly. If copying an ONNX model or IP, consider using [finn_helper.py](#finn_helperpy) to help.
- Function:
  - Creates a logical file of all the nodes in the parent model, including nodes found in child models attached to the parent model.
- Output:
  - Returns a logical file in dictionary form, assigning each node an ID and its AXIS connection destination. Will operate recursively if it discovers StreamingDataFlowPartition nodes pointing to child models.

# finn_helper.py
## finn_helper Requirements
This script must be copied into, or run inside, a FINN docker container.
## finn_helper API
**attach_child_models_to_parent_model(parent_model, ordered_list_of_child_model_paths):**
- Input:
  - parent_model: A FINN ModelWrapper object representing the FINN parent model.
  - ordered_list_of_child_model_paths: a list of strings representing the filepaths of each of the child models to be attached to the parent model.
    - List must be ordered (the child model filepath at entry 0 will be attached to the first StreamingDataFlowPartition node encountered in the parent model, whose nodes are traversed in-order).
    - List must contain the same number of entries as the number of StreamingDataFlowPartition nodes in the parent_model.
- Function:
  - Modifies the "model" attribute of the StreamingDataFlowPartition nodes in the parent_model, inserting the filepaths of the child models in order.
- Output:
  - modified parent_model

**compare_contexts(context_a, context_b)**
- Input:
  - context_a: Context collected from testing an ONNX model with return_full_exec_context set to `True`.
  - context_b: Context collected from testing an ONNX model with return_full_exec_context set to `True`.
  - context_a and context_b should be two contexts collected from testing the **same** ONNX model using different testing modes (eg cppsim vs rtlsim vs software) or at different stages in the end to end flow.
- Function:
  - Compares two contexts collected from running an identical ONNX model using two different testing modes. Used to help debug rtlsim and cppsim tests by comparing them to a context run in software.
  - Software context should be considered the golden.
- Output:
  - If discrepancies are found between contexts, they will be printed out.
  
**copy_ip(model, copy_dir, src_dir):**
- Input:
  - model: an ONNX model which contains accelerated nodes that have hardware IP generated for them (typically the child model).
  - copy_dir: The absolute path to the directory that all IP will be copied to.
  - src_dir: The directory where all IP are currently located (typically /tmp/finn_dev_*)
- Function:
  - Traverses the model. Any core which has had IP generated for it has its IP copied from src_dir to copy_dir, and its `code_gen_dir_ipgen`, `ipgen_path`, `ip_path` attributes are updated. 
  - Additionally, if FINN has generated a Vivado stitched IP project for this model, that model is also copied to copy_dir, and the attribute pointing to this project is updated. 
- Output:
  - A modified version of model, where cores with IP have IP attributes that now point to the copied IP located in copy_dir.
  - This model is functionally correct, and can be tested using RTLSim.

**copy_onnx_model(parent_model_path, new_path, ip_src_path="/tmp/finn_dev_justin"):**
IMPORTANT: There is currently a bug with this function. This function requires all verilog paths to be relative, but this can lead to incorrect behaviour when the IP is simulated or synthesized. A workaround is to leave all verilog paths relative until after the ONNX model and all IP have been copied to their final location.
- Input:
  - parent_model_path: String containing the absolute filepath to a parent_model.
  - new_path: String containing the absolute path to the directory where the parent_model, any child_models and all associated IP will be copied into.
  - ip_src_path: String containing the absolute path to the directory where the generated IP for parent/child models was generated by FINN (typically /tmp/finn_dev_*). 
  - IMPORTANT: All verilog paths must be relative for this function to work successfully (when generating IP do NOT run the transform ReplaceVerilogRelpaths)
- Function:
  - Traverses the model. Any nodes in this model and any child models attached to this model that have generated IP have their IP copied into new_path. 
  - The child models are also copied into new_path, and the parent model's StreamingDataFlowPartition nodes are updated with the new child model filepaths.
  - Finally, a copy of the new parent model is saved to new_path.
- Output:
  - Returns a string containing the absolute filepath to the new parent model.

**create_test_data(model="TFC"):**
- Input:
  - model: a trained example model supplied by finn in finn.util.test.get_test_model_trained ("TFC", "SFC")
- Function:
  - Generates a test input vector, runs it through the trained example model, generating a golden output value for comparisons when running other tests.
- Output:
  - input_dict: dictionary with entry "global_in" containing the test input vector.
    -  "global_in" must be renamed to match the name of your model's input
  - golden: The golden output vector generated by the trained example model.

**test_partitioned_model_using_cppsim(stage, parent_model, list_of_child_models, input_dict, produced_golden):**
- Input:
  - stage: String that allows the user to track at what stage in the flow this function was run (eg. Stage = "Transforming Folding Factors") (can be left blank if desired)
  - parent_model: a Modelwrapper object representing the parent_model.
  - list_of_child_models: An ordered list of Modelwrapper objects of child models attached to the parent model.
    - List must be ordered (the child model at entry 0 will be attached to the first StreamingDataFlowPartition node encountered in the parent model, whose nodes are traversed in-order).
    - List must contain the same number of entries as the number of StreamingDataFlowPartition nodes in the parent_model.
  - input_dict: Dictionary containing the test input vector. 
    - Dictionary key must match the name of the parent_model's input.
  - produced_golden: A golden output vector generated from running the test input vector through the same model using software.
- Function:
  - Makes a deep copy of the parent and child models, then applies transforms to them to prepare them for simulation using a C++ based simulator.
  - Simulates inference using the test input vector, then compares the result with the golden output.
- Output:
  - Prints the simulation and golden outputs, and whether or not they are close enough to be considered the same.

**test_partitioned_model_using_rtlsim(stage, parent_model, list_of_child_models, input_dict, produced_golden, src_dir="/tmp/finn_dev_justin", return_full_exec_context=False):**
- Input:
  - stage: String that allows the user to track at what stage in the flow this function was run (eg. Stage = "Transforming Folding Factors") (can be left blank if desired)
  - parent_model: a Modelwrapper object representing the parent_model.
  - list_of_child_models: An ordered list of Modelwrapper objects of child models attached to the parent model.
    - List must be ordered (the child model at entry 0 will be attached to the first StreamingDataFlowPartition node encountered in the parent model, whose nodes are traversed in-order).
    - List must contain the same number of entries as the number of StreamingDataFlowPartition nodes in the parent_model.
  - input_dict: Dictionary containing the test input vector. 
    - Dictionary key must match the name of the parent_model's input.
  - produced_golden: A golden output vector generated from running the test input vector through the same model using software.
  - src_dir: String containing the absolute path to the directory where IP generated by FINN for these models is stored (typically /tmp/finn_dev_*).
  - return_full_exec_context: When set to True, will return execution context containing intermediate signals from running the simulation, including the values of the weights, inputs and outputs of all cores. 
- Function:
  - Makes a deep copy of the parent and child models and all generated IP, then applies transforms to them to prepare them for simulation using an RTL simulator.
  - Simulates inference using the test input vector, then compares the result with the golden output.
- Output:
  - if return_full_exec_context is True: returns a dictionary containing the full context of the simulation, final output vector included.
  - else: returns the final output vector.

**test_onnx_model(stage, model, input_dict, produced_golden, output_name="global_out", return_full_exec_context=False):**
- Input:
  - stage: String that allows the user to track at what stage in the flow this function was run (eg. Stage = "Transforming Folding Factors") (can be left blank if desired)
  - model: a Modelwrapper object representing the parent_model.
  - input_dict: Dictionary containing the test input vector. 
    - Dictionary key must match the name of the parent_model's input.
  - produced_golden: A golden output vector generated from running the test input vector through the same model using software.
  - output_name: The name of the output of the model.
  - return_full_exec_context: When set to True, will return execution context containing intermediate signals from running the simulation, including the values of the weights, inputs and outputs of all cores. 
- Function:
  - Runs inference of the test input vector on the provided model, comparing the result to produced_golden.
  - Will automatically detect whether to run the model using software, cppsim, or rtlsim.
- Output:
  - if return_full_exec_context is True: returns a dictionary containing the full context of the simulation, final output vector included.
  - else: returns the final output vector.
